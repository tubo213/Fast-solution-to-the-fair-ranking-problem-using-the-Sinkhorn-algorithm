# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false

-e file:.
aiohttp==3.9.5
    # via fsspec
aiosignal==1.3.1
    # via aiohttp
antlr4-python3-runtime==4.9.3
    # via hydra-core
    # via omegaconf
attrs==23.2.0
    # via aiohttp
certifi==2022.12.7
    # via requests
charset-normalizer==2.1.1
    # via requests
clarabel==0.6.0
    # via cvxpy
cvxpy==1.4.1
    # via nsw-with-optimal-transport
cython==3.0.10
    # via nsw-with-optimal-transport
ecos==2.0.12
    # via cvxpy
filelock==3.9.0
    # via torch
    # via triton
frozenlist==1.4.1
    # via aiohttp
    # via aiosignal
fsspec==2023.4.0
    # via lightning
    # via pytorch-lightning
    # via torch
hydra-core==1.3.2
    # via nsw-with-optimal-transport
idna==3.4
    # via requests
    # via yarl
jinja2==3.1.2
    # via torch
joblib==1.3.2
    # via scikit-learn
lightning==2.2.4
    # via nsw-with-optimal-transport
lightning-utilities==0.11.2
    # via lightning
    # via pytorch-lightning
    # via torchmetrics
loguru==0.7.2
    # via nsw-with-optimal-transport
markupsafe==2.1.3
    # via jinja2
mosek==10.1.21
    # via cvxpy
mpmath==1.3.0
    # via sympy
multidict==6.0.5
    # via aiohttp
    # via yarl
networkx==3.2.1
    # via torch
numpy==1.26.3
    # via clarabel
    # via cvxpy
    # via ecos
    # via lightning
    # via mosek
    # via nsw-with-optimal-transport
    # via osqp
    # via pandas
    # via pytorch-lightning
    # via qdldl
    # via scikit-learn
    # via scipy
    # via scs
    # via torchmetrics
nvidia-cublas-cu12==12.1.3.1
    # via nvidia-cudnn-cu12
    # via nvidia-cusolver-cu12
    # via torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==8.9.2.26
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via nvidia-cusolver-cu12
    # via torch
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.1.105
    # via nvidia-cusolver-cu12
    # via nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
omegaconf==2.3.0
    # via hydra-core
osqp==0.6.3
    # via cvxpy
packaging==22.0
    # via hydra-core
    # via lightning
    # via lightning-utilities
    # via pytorch-lightning
    # via torchmetrics
pandas==2.1.3
    # via nsw-with-optimal-transport
pybind11==2.11.1
    # via cvxpy
python-dateutil==2.8.2
    # via pandas
pytorch-lightning==2.2.4
    # via lightning
pytz==2023.3.post1
    # via pandas
pyyaml==6.0.1
    # via lightning
    # via omegaconf
    # via pytorch-lightning
qdldl==0.1.7.post0
    # via osqp
requests==2.28.1
    # via fsspec
scikit-learn==1.3.2
    # via nsw-with-optimal-transport
scipy==1.11.4
    # via clarabel
    # via cvxpy
    # via ecos
    # via nsw-with-optimal-transport
    # via osqp
    # via qdldl
    # via scikit-learn
    # via scs
scs==3.2.4.post1
    # via cvxpy
setuptools==69.5.1
    # via lightning-utilities
six==1.16.0
    # via python-dateutil
sympy==1.12
    # via torch
threadpoolctl==3.2.0
    # via scikit-learn
torch==2.3.0+cu121
    # via lightning
    # via nsw-with-optimal-transport
    # via pytorch-lightning
    # via torchmetrics
torchmetrics==1.0.3
    # via lightning
    # via pytorch-lightning
tqdm==4.64.1
    # via lightning
    # via pytorch-lightning
triton==2.3.0
    # via torch
typing-extensions==4.8.0
    # via lightning
    # via lightning-utilities
    # via pytorch-lightning
    # via torch
tzdata==2023.3
    # via pandas
urllib3==1.26.13
    # via requests
yarl==1.9.4
    # via aiohttp
